{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipython-autotime\n",
      "  Downloading ipython-autotime-0.1.tar.bz2 (1.2 kB)\n",
      "Could not build wheels for ipython-autotime, since package 'wheel' is not installed.\n",
      "Installing collected packages: ipython-autotime\n",
      "    Running setup.py install for ipython-autotime ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed ipython-autotime-0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 628 Âµs\n"
     ]
    }
   ],
   "source": [
    "cd = {1:4, 2:6, 3:1, 4:8, 5:3, 10:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for key in cd.keys():\n",
    "    for i in range(cd[key]):\n",
    "        list.append(key)\n",
    "list = sorted(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    list = []\n",
    "    for key in count_dict.keys():\n",
    "        for i in range(count_dict[key]):\n",
    "            list.append(key)\n",
    "    list = sorted(list)\n",
    "    midpoint = len(list)//2\n",
    "    if len(list)%2 == 0:\n",
    "        median = (list[midpoint] + list[midpoint-1])//2\n",
    "    else:\n",
    "        median = list[midpoint]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median_old(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    return sk[my_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = {4: 10, 236: 13, 99: 43, 88: 43, 127: 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd2 = {4: 10, 236: 13, 99: 43, 88: 43, 127: 14, 8:102}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_median1 = quick_median(cd)\n",
    "my_median2 = quick_median(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_deviation_from_median1(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median1(count_dict)\n",
    "    deviations = {}\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        X_value = abs(key - my_median)\n",
    "        deviations[X_value] = count_dict[key]\n",
    "    print(deviations)\n",
    "    return quick_median1(deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_deviation_from_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted([abs(x-99) for x in list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd3 = {1:100, 100:100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median1(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_new(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frags1(file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_dict = {}\n",
    "    PRINT_EVERY = 100000\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                if myTlen not in count_dict:\n",
    "                    count_dict[myTlen] = 0\n",
    "                count_dict[myTlen] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = count_frags(\"C:/Users/joshf/Documents/work_stuff/neat_data/baby.sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "count_dict = {}\n",
    "PRINT_EVERY = 100000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in file_to_parse:\n",
    "    # Need to convert bam iterable objects into strings for the next part\n",
    "    line = str(item)\n",
    "    # Skip all comments and headers\n",
    "    if line[0] == '#' or line[0] == '@':\n",
    "        continue\n",
    "    splt = line.strip().split('\\t')\n",
    "    samFlag = int(splt[1])\n",
    "    myRef = splt[2]\n",
    "    mapQual = int(splt[4])\n",
    "    mateRef = splt[6]\n",
    "    myTlen = abs(int(splt[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probs1(count_dict: dict) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median1(count_dict)\n",
    "    mdm = median_deviation_from_median1(count_dict)\n",
    "\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        if 0 < key < med + FILTER_MEDDEV_M * mdm:\n",
    "            if count_dict[key] >= FILTER_MINREADS:\n",
    "                print(key, count_dict[key])\n",
    "                values.append(key)\n",
    "                probabilities.append(count_dict[key])\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_probs(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = count_frags(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = wrapper(quick_median, cd)\n",
    "timeit.timeit(wrapped, number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped2 = wrapper(quick_median_new, cd)\n",
    "timeit.timeit(wrapped2, number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "def quick_median_new2(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    print(mid_point)\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            my_ind += 1\n",
    "            break\n",
    "        my_ind += 1\n",
    "    # correction if we miss the mark too far\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.22 ms\n"
     ]
    }
   ],
   "source": [
    "count_d = {1:4, 2:6, 3:3, 4:8, 5:3, 10:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.65 ms\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "for key in count_d.keys():\n",
    "    for i in range(count_d[key]):\n",
    "        list.append(key)\n",
    "list = sorted(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.68 ms\n"
     ]
    }
   ],
   "source": [
    "(list[13] + list[12])//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.58 ms\n"
     ]
    }
   ],
   "source": [
    "quick_median_new2(count_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frags_new(file: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_list = []\n",
    "    PRINT_EVERY = 100000\n",
    "    i = 0\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                count_list.append(myTlen)\n",
    "    count_list = sorted(count_list)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped3 = wrapper(count_frags, \"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "timeit.timeit(wrapped3, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped4 = wrapper(count_frags_new, \"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "timeit.timeit(wrapped4, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    midpoint = len(datalist)//2\n",
    "    if len(datalist) % 2 == 0:\n",
    "        median = (datalist[midpoint] + datalist[midpoint-1])/2\n",
    "    else:\n",
    "        median = datalist[midpoint]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_deviation_from_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median_new(datalist)\n",
    "    deviations = []\n",
    "    for item in datalist:\n",
    "        X_value = abs(item - my_median)\n",
    "        deviations.append(X_value)\n",
    "    return quick_median_new(sorted(deviations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_deviation_from_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probs_new(datalist: list) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median_new(datalist)\n",
    "    mdm = median_deviation_from_median_new(datalist)\n",
    "    \n",
    "    for item in list(set(datalist)):\n",
    "        if 0 < item < med + FILTER_MEDDEV_M * mdm:\n",
    "            if datalist.count(item) >= FILTER_MINREADS:\n",
    "                values.append(item)\n",
    "                probabilities.append(datalist.count(item))\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x == 10 for x in cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list.count(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing probs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100],\n",
       " [0.0014269858886951008,\n",
       "  0.0019132181174356536,\n",
       "  0.0021669044976481157,\n",
       "  0.0028539717773902015,\n",
       "  0.0024734422070715077,\n",
       "  0.007071507848422388,\n",
       "  0.00800169124253475,\n",
       "  0.007927699381639449,\n",
       "  0.008033402040061307,\n",
       "  0.007853707520744147,\n",
       "  0.03276782411077639,\n",
       "  0.0322287405528249,\n",
       "  0.03289466730088262,\n",
       "  0.03376142909994186,\n",
       "  0.02844458538132234,\n",
       "  0.23078061413244544,\n",
       "  0.21153216003382486,\n",
       "  0.1821996723217589,\n",
       "  0.16061518947201522,\n",
       "  0.005052587072564875])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counting_list = count_frags_new(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "print(\"computing probs\")\n",
    "compute_probs_new(counting_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the two competing compute frag length programs, so that I can run side-by-side time comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Count_dict method\n",
    "\n",
    "def quick_median1(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median\n",
    "\n",
    "\n",
    "def median_deviation_from_median1(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median1(count_dict)\n",
    "    deviations = {}\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        X_value = abs(key - my_median)\n",
    "        deviations[X_value] = count_dict[key]\n",
    "    return quick_median1(deviations)\n",
    "\n",
    "\n",
    "def count_frags1(file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_dict = {}\n",
    "    PRINT_EVERY = 100000\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                if myTlen not in count_dict:\n",
    "                    count_dict[myTlen] = 0\n",
    "                count_dict[myTlen] += 1\n",
    "    return count_dict\n",
    "\n",
    "\n",
    "def compute_probs1(count_dict: dict) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median1(count_dict)\n",
    "    mdm = median_deviation_from_median1(count_dict)\n",
    "\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        if 0 < key < med + FILTER_MEDDEV_M * mdm:\n",
    "            if count_dict[key] >= FILTER_MINREADS:\n",
    "                values.append(key)\n",
    "                probabilities.append(count_dict[key])\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24min 3s\n"
     ]
    }
   ],
   "source": [
    "counting_list = count_frags1(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{81: 13, 80: 3, 79: 8, 78: 4, 77: 2, 76: 5, 75: 6, 74: 7, 73: 9, 72: 13, 71: 3, 70: 5, 69: 9, 68: 3, 67: 9, 66: 2, 65: 8, 64: 6, 63: 7, 62: 6, 61: 7, 60: 10, 59: 10, 58: 5, 57: 12, 56: 8, 55: 5, 54: 5, 53: 12, 52: 8, 51: 12, 50: 5, 49: 11, 48: 11, 47: 7, 46: 10, 45: 10, 44: 14, 43: 8, 42: 5, 41: 10, 40: 7, 39: 13, 38: 7, 37: 10, 36: 16, 35: 6, 34: 11, 33: 9, 32: 16, 31: 14, 30: 9, 29: 25, 28: 19, 27: 20, 26: 17, 25: 23, 24: 34, 23: 55, 22: 42, 21: 37, 20: 81, 19: 135, 18: 181, 17: 205, 16: 270, 15: 234, 14: 669, 13: 757, 12: 750, 11: 760, 10: 743, 9: 3100, 8: 3049, 7: 3112, 6: 3194, 5: 2691, 4: 21833, 3: 20012, 2: 17237, 1: 12661399, 0: 478}\n",
      "81 135\n",
      "82 181\n",
      "83 205\n",
      "84 270\n",
      "85 234\n",
      "86 669\n",
      "87 757\n",
      "88 750\n",
      "89 760\n",
      "90 743\n",
      "91 3100\n",
      "92 3049\n",
      "93 3112\n",
      "94 3194\n",
      "95 2691\n",
      "96 21833\n",
      "97 20012\n",
      "98 17237\n",
      "99 15195\n",
      "100 478\n",
      "101 12661399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100,\n",
       "  101],\n",
       " [1.0583251620178232e-05,\n",
       "  1.4189396616683407e-05,\n",
       "  1.607086357138176e-05,\n",
       "  2.1166503240356464e-05,\n",
       "  1.8344302808308934e-05,\n",
       "  5.244589136221657e-05,\n",
       "  5.934460352944386e-05,\n",
       "  5.879584233432351e-05,\n",
       "  5.9579786898781155e-05,\n",
       "  5.824708113920316e-05,\n",
       "  0.0002430228149818705,\n",
       "  0.0002390246977031365,\n",
       "  0.00024396354845921967,\n",
       "  0.0002503918938877724,\n",
       "  0.00021095948229555274,\n",
       "  0.00171158616758038,\n",
       "  0.0015688298623926426,\n",
       "  0.0013512852457556457,\n",
       "  0.0011912037656933942,\n",
       "  3.747255018107551e-05,\n",
       "  0.9925834924479484])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.4 ms\n"
     ]
    }
   ],
   "source": [
    "compute_probs1(counting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.3 ms\n"
     ]
    }
   ],
   "source": [
    "# Datalist method\n",
    "\n",
    "def quick_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    midpoint = len(datalist)//2\n",
    "    if len(datalist) % 2 == 0:\n",
    "        median = (datalist[midpoint] + datalist[midpoint-1])/2\n",
    "    else:\n",
    "        median = datalist[midpoint]\n",
    "    return median\n",
    "\n",
    "\n",
    "def median_deviation_from_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median_new(datalist)\n",
    "    deviations = []\n",
    "    for item in datalist:\n",
    "        X_value = abs(item - my_median)\n",
    "        deviations.append(X_value)\n",
    "    return quick_median_new(sorted(deviations))\n",
    "\n",
    "\n",
    "def count_frags_new(file: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_list = []\n",
    "    PRINT_EVERY = 100000\n",
    "    i = 0\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                count_list.append(myTlen)\n",
    "    count_list = sorted(count_list)\n",
    "    file_to_parse.close()\n",
    "    return count_list\n",
    "\n",
    "\n",
    "def compute_probs_new(datalist: list) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median_new(datalist)\n",
    "    mdm = median_deviation_from_median_new(datalist)\n",
    "    \n",
    "    for item in list(set(datalist)):\n",
    "        if 0 < item < med + FILTER_MEDDEV_M * mdm:\n",
    "            data_count = datalist.count(item)\n",
    "            if data_count >= FILTER_MINREADS:\n",
    "                values.append(item)\n",
    "                probabilities.append(data_count)\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18min 4s\n"
     ]
    }
   ],
   "source": [
    "counting_list = count_frags_new(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  96,\n",
       "  97,\n",
       "  98,\n",
       "  99,\n",
       "  100],\n",
       " [0.0014269858886951008,\n",
       "  0.0019132181174356536,\n",
       "  0.0021669044976481157,\n",
       "  0.0028539717773902015,\n",
       "  0.0024734422070715077,\n",
       "  0.007071507848422388,\n",
       "  0.00800169124253475,\n",
       "  0.007927699381639449,\n",
       "  0.008033402040061307,\n",
       "  0.007853707520744147,\n",
       "  0.03276782411077639,\n",
       "  0.0322287405528249,\n",
       "  0.03289466730088262,\n",
       "  0.03376142909994186,\n",
       "  0.02844458538132234,\n",
       "  0.23078061413244544,\n",
       "  0.21153216003382486,\n",
       "  0.1821996723217589,\n",
       "  0.16061518947201522,\n",
       "  0.005052587072564875])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "compute_probs_new(counting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
