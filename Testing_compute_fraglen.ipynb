{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = {1:4, 2:6, 3:1, 4:8, 5:3, 10:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for key in cd.keys():\n",
    "    for i in range(cd[key]):\n",
    "        list.append(key)\n",
    "list = sorted(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    list = []\n",
    "    for key in count_dict.keys():\n",
    "        for i in range(count_dict[key]):\n",
    "            list.append(key)\n",
    "    list = sorted(list)\n",
    "    midpoint = len(list)//2\n",
    "    if len(list)%2 == 0:\n",
    "        median = (list[midpoint] + list[midpoint-1])//2\n",
    "    else:\n",
    "        median = list[midpoint]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median_old(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    return sk[my_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = {4: 10, 236: 13, 99: 43, 88: 43, 127: 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd2 = {4: 10, 236: 13, 99: 43, 88: 43, 127: 14, 8:102}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_median1 = quick_median(cd)\n",
    "my_median2 = quick_median(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_deviation_from_median1(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median1(count_dict)\n",
    "    deviations = {}\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        X_value = abs(key - my_median)\n",
    "        deviations[X_value] = count_dict[key]\n",
    "    print(deviations)\n",
    "    return quick_median1(deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_deviation_from_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted([abs(x-99) for x in list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd3 = {1:100, 100:100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_old(cd3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median1(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_new(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frags1(file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_dict = {}\n",
    "    PRINT_EVERY = 100000\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                if myTlen not in count_dict:\n",
    "                    count_dict[myTlen] = 0\n",
    "                count_dict[myTlen] += 1\n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = count_frags(\"C:/Users/joshf/Documents/work_stuff/neat_data/baby.sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "count_dict = {}\n",
    "PRINT_EVERY = 100000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in file_to_parse:\n",
    "    # Need to convert bam iterable objects into strings for the next part\n",
    "    line = str(item)\n",
    "    # Skip all comments and headers\n",
    "    if line[0] == '#' or line[0] == '@':\n",
    "        continue\n",
    "    splt = line.strip().split('\\t')\n",
    "    samFlag = int(splt[1])\n",
    "    myRef = splt[2]\n",
    "    mapQual = int(splt[4])\n",
    "    mateRef = splt[6]\n",
    "    myTlen = abs(int(splt[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probs1(count_dict: dict) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median1(count_dict)\n",
    "    mdm = median_deviation_from_median1(count_dict)\n",
    "\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        if 0 < key < med + FILTER_MEDDEV_M * mdm:\n",
    "            if count_dict[key] >= FILTER_MINREADS:\n",
    "                print(key, count_dict[key])\n",
    "                values.append(key)\n",
    "                probabilities.append(count_dict[key])\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_probs(cd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = count_frags(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = wrapper(quick_median, cd)\n",
    "timeit.timeit(wrapped, number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped2 = wrapper(quick_median_new, cd)\n",
    "timeit.timeit(wrapped2, number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median_new2(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    print(mid_point)\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            my_ind += 1\n",
    "            break\n",
    "        my_ind += 1\n",
    "    # correction if we miss the mark too far\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_d = {1:4, 2:6, 3:3, 4:8, 5:3, 10:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for key in count_d.keys():\n",
    "    for i in range(count_d[key]):\n",
    "        list.append(key)\n",
    "list = sorted(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list[13] + list[12])//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median_new2(count_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frags_new(file: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_list = []\n",
    "    PRINT_EVERY = 100000\n",
    "    i = 0\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                count_list.append(myTlen)\n",
    "    count_list = sorted(count_list)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped3 = wrapper(count_frags, \"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "timeit.timeit(wrapped3, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped4 = wrapper(count_frags_new, \"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "timeit.timeit(wrapped4, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    midpoint = len(datalist)//2\n",
    "    if len(datalist) % 2 == 0:\n",
    "        median = (datalist[midpoint] + datalist[midpoint-1])/2\n",
    "    else:\n",
    "        median = datalist[midpoint]\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_deviation_from_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median_new(datalist)\n",
    "    deviations = []\n",
    "    for item in datalist:\n",
    "        X_value = abs(item - my_median)\n",
    "        deviations.append(X_value)\n",
    "    return quick_median_new(sorted(deviations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_deviation_from_median(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probs_new(datalist: list) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median_new(datalist)\n",
    "    mdm = median_deviation_from_median_new(datalist)\n",
    "    \n",
    "    for item in list(set(datalist)):\n",
    "        if 0 < item < med + FILTER_MEDDEV_M * mdm:\n",
    "            if datalist.count(item) >= FILTER_MINREADS:\n",
    "                values.append(item)\n",
    "                probabilities.append(datalist.count(item))\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x == 10 for x in cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list.count(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_list = count_frags_new(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")\n",
    "print(\"computing probs\")\n",
    "compute_probs_new(counting_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the two competing compute frag length programs, so that I can run side-by-side time comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_dict method\n",
    "\n",
    "def quick_median1(count_dict: dict) -> int:\n",
    "    mid_point = sum(count_dict.values()) / 2\n",
    "    my_sum = 0\n",
    "    my_ind = 0\n",
    "    sk = sorted(count_dict.keys())\n",
    "    while my_sum < mid_point:\n",
    "        my_sum += count_dict[sk[my_ind]]\n",
    "        if my_sum >= mid_point:\n",
    "            break\n",
    "        my_ind += 1\n",
    "    if sum(count_dict.values())%2 == 0:\n",
    "        median = (sk[my_ind] + sk[my_ind-1])//2\n",
    "    else:\n",
    "        median = sk[my_ind]\n",
    "    return median\n",
    "\n",
    "\n",
    "def median_deviation_from_median1(count_dict: dict) -> int:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median1(count_dict)\n",
    "    deviations = {}\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        X_value = abs(key - my_median)\n",
    "        deviations[X_value] = count_dict[key]\n",
    "    return quick_median1(deviations)\n",
    "\n",
    "\n",
    "def count_frags1(file: str) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_dict = {}\n",
    "    PRINT_EVERY = 100000\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                if myTlen not in count_dict:\n",
    "                    count_dict[myTlen] = 0\n",
    "                count_dict[myTlen] += 1\n",
    "    return count_dict\n",
    "\n",
    "\n",
    "def compute_probs1(count_dict: dict) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median1(count_dict)\n",
    "    mdm = median_deviation_from_median1(count_dict)\n",
    "\n",
    "    for key in sorted(count_dict.keys()):\n",
    "        if 0 < key < med + FILTER_MEDDEV_M * mdm:\n",
    "            if count_dict[key] >= FILTER_MINREADS:\n",
    "                values.append(key)\n",
    "                probabilities.append(count_dict[key])\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_list = count_frags1(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_probs1(counting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datalist method\n",
    "\n",
    "def quick_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    Finds the median of a counting dictionary\n",
    "    :param count_dict: the counting dictionary to find the median of\n",
    "    :return: integer index of the location of the median\n",
    "    \"\"\"\n",
    "    midpoint = len(datalist)//2\n",
    "    if len(datalist) % 2 == 0:\n",
    "        median = (datalist[midpoint] + datalist[midpoint-1])/2\n",
    "    else:\n",
    "        median = datalist[midpoint]\n",
    "    return median\n",
    "\n",
    "\n",
    "def median_deviation_from_median_new(datalist: list) -> float:\n",
    "    \"\"\"\n",
    "    calculates the deviation from the median of each element of counting dictionary,\n",
    "    then returns the median of that dictionary\n",
    "    :param count_dict: Counting dictionary to analyze\n",
    "    :return: index of median of the deviations\n",
    "    \"\"\"\n",
    "    my_median = quick_median_new(datalist)\n",
    "    deviations = []\n",
    "    for item in datalist:\n",
    "        X_value = abs(item - my_median)\n",
    "        deviations.append(X_value)\n",
    "    return quick_median_new(sorted(deviations))\n",
    "\n",
    "\n",
    "def count_frags_new(file: str) -> list:\n",
    "    \"\"\"\n",
    "    Takes a sam file input and creates a counting dictionary of the number of reads that are paired,\n",
    "    first in the pair, confidently mapped and whose pair is mapped to the same reference\n",
    "    :param file: A sam input file\n",
    "    :return: A dictionary of the counts of the above reads\n",
    "    \"\"\"\n",
    "    FILTER_MAPQUAL = 10  # only consider reads that are mapped with at least this mapping quality\n",
    "    count_list = []\n",
    "    PRINT_EVERY = 100000\n",
    "    i = 0\n",
    "    # Check if the file is sam or bam and decide how to open based on that\n",
    "    if file[-4:] == \".sam\":\n",
    "        file_to_parse = open(file, 'r')\n",
    "    elif file[-4:] == \".bam\":\n",
    "        file_to_parse = pysam.AlignmentFile(file, 'rb')\n",
    "    else:\n",
    "        print(\"Unknown file type, must be bam or sam\")\n",
    "        exit(1)\n",
    "\n",
    "    for item in file_to_parse:\n",
    "        # Need to convert bam iterable objects into strings for the next part\n",
    "        line = str(item)\n",
    "        # Skip all comments and headers\n",
    "        if line[0] == '#' or line[0] == '@':\n",
    "            continue\n",
    "        splt = line.strip().split('\\t')\n",
    "        samFlag = int(splt[1])\n",
    "        myRef = splt[2]\n",
    "        mapQual = int(splt[4])\n",
    "        mateRef = splt[6]\n",
    "        myTlen = abs(int(splt[8]))\n",
    "\n",
    "        # if read is paired, and is first in pair, and is confidently mapped...\n",
    "        if samFlag & 1 and samFlag & 64 and mapQual > FILTER_MAPQUAL:\n",
    "            # and mate is mapped to same reference\n",
    "            if mateRef == '=' or mateRef == myRef:\n",
    "                count_list.append(myTlen)\n",
    "    count_list = sorted(count_list)\n",
    "    file_to_parse.close()\n",
    "    return count_list\n",
    "\n",
    "\n",
    "def compute_probs_new(datalist: list) -> (list, list):\n",
    "    \"\"\"\n",
    "    Computes the probabilities for fragments with at least 100 pairs supporting it and that are at least 10 median\n",
    "    deviations from the median.\n",
    "    :param count_dict: A dictionary of fragments with counts\n",
    "    :return: A list of values that meet the criteria and a list of -their associated probabilities\n",
    "    \"\"\"\n",
    "    FILTER_MINREADS = 100  # only consider fragment lengths that have at least this many read pairs supporting it\n",
    "    FILTER_MEDDEV_M = 10  # only consider fragment lengths this many median deviations above the median\n",
    "    values = []\n",
    "    probabilities = []\n",
    "    med = quick_median_new(datalist)\n",
    "    mdm = median_deviation_from_median_new(datalist)\n",
    "    \n",
    "    for item in list(set(datalist)):\n",
    "        if 0 < item <= med + FILTER_MEDDEV_M * mdm:\n",
    "            data_count = datalist.count(item)\n",
    "            if data_count >= FILTER_MINREADS:\n",
    "                values.append(item)\n",
    "                probabilities.append(data_count)\n",
    "    count_sum = float(sum(probabilities))\n",
    "    probabilities = [n / count_sum for n in probabilities]\n",
    "    return values, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_list = count_frags_new(\"/home/joshfactorial/Documents/neat_data/WGS_chr20_21_22_normal.bam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_probs_new(counting_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = {50:10, 75: 10, 100:1000}\n",
    "\n",
    "datalist = []\n",
    "for key in cd.keys():\n",
    "    for i in range(cd[key]):\n",
    "        datalist.append(key)\n",
    "datalist = sorted(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_median_new(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([100], [1.0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_probs_new(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
