"""
Functions and classes for writing out the output.

TODO This file is in serious need of refactoring.
"""

__all__ = ["OutputFileWriter"]

import gzip
import re
import shutil
import time
from struct import pack
import logging
import pickle

from Bio import bgzf
from Bio import SeqIO
from pathlib import Path
from numpy.random import Generator

from ...common import validate_output_path, open_output, open_input
from .read import Read
from .options import Options

_LOG = logging.getLogger(__name__)


# Some Constants
# TODO make bam compression a configurable option
BAM_COMPRESSION_LEVEL = 6
CIGAR_PACKED = {"M": 0, "I": 1, "D": 2, "N": 3, "S": 4, "H": 5, "P": 6, "=": 7, "X": 8}
SEQ_PACKED = {
    "=": 0,
    "A": 1,
    "C": 2,
    "M": 3,
    "G": 4,
    "R": 5,
    "S": 6,
    "V": 7,
    "T": 8,
    "W": 9,
    "Y": 10,
    "H": 11,
    "K": 12,
    "D": 13,
    "B": 14,
    "N": 15,
}
# TODO figure out an optimum batch size or get rid of this idea
BUFFER_BATCH_SIZE = 8000  # write out to file after this many reads


def reg2bin(beg: int, end: int):
    """
    Samtools reg2bin function.

    Finds the largest superset bin of region. Numeric values taken from hts-specs
    Note: description of this function taken from source code for bamnostic.bai
        (https://bamnostic.readthedocs.io/en/latest/_modules/bamnostic/bai.html)
    :param beg: inclusive beginning position of region
    :param end: exclusive end position of region
    :return: distinct bin ID or largest superset bin of region
    """
    end -= 1
    if beg >> 14 == end >> 14:
        return ((1 << 15) - 1) // 7 + (beg >> 14)
    if beg >> 17 == end >> 17:
        return ((1 << 12) - 1) // 7 + (beg >> 17)
    if beg >> 20 == end >> 20:
        return ((1 << 9) - 1) // 7 + (beg >> 20)
    if beg >> 23 == end >> 23:
        return ((1 << 6) - 1) // 7 + (beg >> 23)
    if beg >> 26 == end >> 26:
        return ((1 << 3) - 1) // 7 + (beg >> 26)
    return 0


class OutputFileWriter:
    """
    This class sets up the output files and has methods for writing out records
    in the various formats.

    :param options: Options for the current run.
    :param bam_header: A dictionary of lengths of each contig from the reference, keyed by contig id.
    """

    def __init__(self, options: Options, bam_header: dict = None):

        # set the booleans
        self.write_fastq = options.produce_fastq
        self.write_bam = options.produce_bam
        self.write_vcf = options.produce_vcf
        self.paired = options.paired_ended
        self.first_fastq_write = True  # New flag for appending FASTQ data

        self.bam_header = bam_header

        # Set the file names

        self.fastq_fns = None
        self.fastq1_fn = None
        self.fastq2_fn = None

        self.bam_fn = None
        self.vcf_fn = None

        # Set up filenames based on booleans
        files_to_write = []
        if self.paired and self.write_fastq:
            self.fastq1_fn = (
                options.output.parent / f"{options.output.stem}_r1.fastq.gz"
            )
            self.fastq2_fn = (
                options.output.parent / f"{options.output.stem}_r2.fastq.gz"
            )
            self.fastq_fns = [self.fastq1_fn, self.fastq2_fn]
            files_to_write.extend(self.fastq_fns)
        elif self.write_fastq:
            self.fastq1_fn = options.output.parent / f"{options.output.stem}.fastq.gz"
            self.fastq2_fn = self.temporary_dir / "dummy.fastq.gz"
            self.fastq_fns = [self.fastq1_fn, self.fastq2_fn]
            files_to_write.extend(self.fastq_fns)
        if self.write_bam:
            self.bam_fn = options.output.parent / f"{options.output.stem}_golden.bam"
            self.bam_keys = list(bam_header)
            files_to_write.append(self.bam_fn)
        if self.write_vcf:
            self.vcf_fn = options.output.parent / f"{options.output.stem}_golden.vcf.gz"
            files_to_write.append(self.vcf_fn)

        self.files_to_write = files_to_write

        # Create files as applicable
        for file in [x for x in self.files_to_write if x.name != "dummy.fastq.gz"]:
            validate_output_path(file, True, options.overwrite_output)

        mode = "xt"
        if options.overwrite_output:
            mode = "wt"
        # Initialize the vcf and write the header, if applicable
        if self.write_vcf:
            # Writing the vcf header.
            with open_output(self.vcf_fn, mode=mode) as vcf_file:
                vcf_file.write(f"##fileformat=VCFv4.1\n")
                vcf_file.write(f"##reference={Path(options.reference).resolve()}\n")
                vcf_file.write(
                    f"##Generated by NEAT with RNG value: {options.rng_seed}\n"
                )
                vcf_file.write(
                    f'##INFO=<ID=DP,Number=1,Type=Integer,Description="Total Depth">\n'
                )
                vcf_file.write(
                    f'##INFO=<ID=AF,Number=A,Type=Float,Description="Allele Frequency">\n'
                )
                vcf_file.write(
                    f"##INFO=<ID=VMX,Number=1,Type=String,"
                    f'Description="SNP is Missense in these Read Frames">\n'
                )
                vcf_file.write(
                    f"##INFO=<ID=VNX,Number=1,Type=String,"
                    f'Description="SNP is Nonsense in these Read Frames">\n'
                )
                vcf_file.write(
                    f'##INFO=<ID=VFX,Number=1,Type=String,Description="Indel Causes Frameshift">\n'
                )
                vcf_file.write(f'##ALT=<ID=DEL,Description="Deletion">\n')
                vcf_file.write(f'##ALT=<ID=DUP,Description="Duplication">\n')
                vcf_file.write(
                    f'##ALT=<ID=INS,Description="Insertion of novel sequence">\n'
                )
                vcf_file.write(f'##ALT=<ID=INV,Description="Inversion">\n')
                vcf_file.write(
                    f'##ALT=<ID=CNV,Description="Copy number variable region">\n'
                )
                vcf_file.write(f'##ALT=<ID=TRANS,Description="Translocation">\n')
                vcf_file.write(
                    f'##ALT=<ID=INV-TRANS,Description="Inverted translocation">\n'
                )
                vcf_file.write(
                    f'##FORMAT=<ID=GT,Number=1,Type=String,Description="Genotype">\n'
                )
                # Add a neat sample column
                vcf_file.write(
                    f"#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tNEAT_simulated_sample\n"
                )

    def write_final_vcf(self, local_files_dict: dict, reference: dict):
        """
        This function takes in a list of temporary vcf files and combines them into a final output

        :param local_files_dict: The list of temporary files to combine
        :param reference: The dictionary of the reference object for this run, to draw refs from
        """
        n_added = 0
        vcf_write_t = time.time()
        with open_output(self.vcf_fn) as vcf_out:
            for contig, variants in local_files_dict.items():
                for location in variants.variant_locations:
                    for variant in variants[location]:
                        ref, alt = variants.get_ref_alt(variant, reference[contig])
                        sample = variants.get_sample_info(variant)

                        # +1 to position because the VCF uses 1-based coordinates
                        #          .id should give the more complete name
                        line = (
                            f"{reference[contig].id}\t"
                            f"{variant.position1 + 1}\t"
                            f"{variants.generate_field(variant, 'ID')}\t"
                            f"{ref}\t"
                            f"{alt}\t"
                            f"{variant.qual_score}\t"
                            f"{variants.generate_field(variant, 'FILTER')}\t"
                            f"{variants.generate_field(variant, 'INFO')}\t"
                            f"{variants.generate_field(variant, 'FORMAT')}\t"
                            f"{sample}\n"
                        )
                        vcf_out.write(line)
                        n_added += 1
        _LOG.info(f"Wrote {n_added} variants in {(time.time() - vcf_write_t)/60:.2f} m")

    def write_fastqs_from_memory(self, reads_data: list, rand_num_gen: Generator):
        """
        Takes lists of in-memory read objects and combines them into final output fastq files.
        The reads are shuffled to make the output more realistic.
        For the first call, files are written (truncated). For subsequent calls, data is appended.

        :param reads_data: A list of tuples, where each tuple contains two lists:
                           (list_of_paired_read_tuples, list_of_singleton_read_tuples).
                           Each read tuple is (Read_object_r1, Read_object_r2) for pairs,
                           or (Read_object, None) for singletons.
        :param rand_num_gen: the random number generator for the run
        """
        all_paired_reads = []
        all_singleton_reads = []
        t = time.time()

        for paired_reads_list, singleton_reads_list in reads_data:
            all_paired_reads.extend(paired_reads_list)
            all_singleton_reads.extend(singleton_reads_list)

        # Shuffle the reads
        rand_num_gen.shuffle(all_paired_reads)
        rand_num_gen.shuffle(all_singleton_reads)

        file_mode = "wt" if self.first_fastq_write else "at"
        wrote_r2 = False  # To check if R2 file actually gets data in paired-end mode

        # Ensure dummy.fastq.gz is handled if not paired, using a temporary path if self.temporary_dir was removed
        # For append mode, opening /dev/null in 'at' might not be ideal, but it's for a dummy file.
        # Let's ensure the dummy file path is valid even if temporary_dir is gone.
        # It's better to ensure dummy_fastq_path is defined and cleaned up if it's a real file.
        dummy_fastq_path = None
        if not self.paired:
            # Create a temporary dummy file path if needed, but it won't be written to in append mode if opened with /dev/null logic
            # The original logic created a dummy file in temporary_dir. If that's gone, we need a placeholder.
            # However, if we are appending, we only care about self.fastq1_fn.
            # The fq2_handle_cm logic needs to be robust.
            if self.fastq2_fn and Path(self.fastq2_fn).name == "dummy.fastq.gz":
                dummy_fastq_path = self.fastq2_fn  # Use the defined dummy path
                # If it's the first write and not paired, dummy.fastq.gz might be created by open_output if path is real.
                # If appending, and not paired, fq2 is effectively /dev/null.

        with open_output(self.fastq1_fn, mode=file_mode) as fq1:
            fq2_cm = (
                open(
                    Path(dummy_fastq_path if dummy_fastq_path else "/dev/null"),
                    (
                        file_mode
                        if dummy_fastq_path and self.first_fastq_write
                        else ("at" if dummy_fastq_path else "a")
                    ),
                )
                if not self.paired
                else open_output(self.fastq2_fn, mode=file_mode)
            )

            with fq2_cm as fq2:
                num_paired_reads = len(all_paired_reads)
                for i in range(num_paired_reads):
                    read1_obj, read2_obj = all_paired_reads[i]
                    fq1.write(read1_obj.to_fastq_string())
                    if self.paired:
                        fq2.write(read2_obj.to_fastq_string())
                        if not wrote_r2:
                            wrote_r2 = True

                num_singleton_reads = len(all_singleton_reads)
                for j in range(num_singleton_reads):
                    read_obj, _ = all_singleton_reads[j]
                    fq1.write(read_obj.to_fastq_string())

        if self.first_fastq_write:
            self.first_fastq_write = False

        # Cleanup dummy file if it was created and is no longer needed.
        # This cleanup should only happen if it's a real file and not /dev/null.
        if (
            not self.paired
            and dummy_fastq_path
            and dummy_fastq_path.exists()
            and dummy_fastq_path.name == "dummy.fastq.gz"
        ):
            # This condition might need refinement: only delete if it was specifically the dummy file we managed.
            # The original logic deleted it if not self.paired.
            # If we are appending, this dummy file might not even be "created" in a meaningful way by later appends.
            # For now, retain original cleanup logic but ensure it targets the specific dummy file.
            if (
                not wrote_r2
            ):  # If R2 was never written to (e.g. single-end or no paired reads)
                try:
                    dummy_fastq_path.unlink(missing_ok=True)
                except (
                    AttributeError
                ):  # In case dummy_fastq_path is not a Path object (e.g. from /dev/null context)
                    pass

        _LOG.info(
            f"Fastq(s) data processed in {(time.time() - t)/60:.2f} m. Mode: {file_mode}"
        )

    def output_bam_file(
        self, all_sam_order_data: list, contig_dict: dict, read_length: int
    ):
        """
        This section is for producing a CIGAR string using in-memory read data.

        :param all_sam_order_data: A list of lists, where each inner list contains
                                   read data (tuples of Read objects) for a contig,
                                   already in SAM order.
        :param contig_dict: A dictionary with the keys as contigs from the reference,
            and the values the index of that contig
        :param read_length: the length of the reads for this run
        """
        t = time.time()
        bam_out = bgzf.BgzfWriter(self.bam_fn, "w", compresslevel=BAM_COMPRESSION_LEVEL)
        bam_out.write("BAM\1")
        header = "@HD\tVN:1.4\tSO:coordinate\n"
        for item in self.bam_header:
            header += f"@SQ\tSN:{item}\tLN:{str(self.bam_header[item])}\n"
        header += "@RG\tID:NEAT\tSM:NEAT\tLB:NEAT\tPL:NEAT\n"
        header_bytes = len(header)
        num_refs = len(self.bam_header)
        bam_out.write(pack("<i", header_bytes))
        bam_out.write(header)
        bam_out.write(pack("<i", num_refs))

        for item in self.bam_header:
            name_length = len(item) + 1
            bam_out.write(pack("<i", name_length))
            bam_out.write(f"{item}\0")
            bam_out.write(pack("<i", self.bam_header[item]))

        for contig_reads_data in all_sam_order_data:  # Iterate through list of lists
            # contig_reads_data is already the list of (read1, read2) tuples (sam_order)
            for read_data_tuple in contig_reads_data:
                read1 = read_data_tuple[0]
                read2 = read_data_tuple[1]
                if read1:
                    self.write_bam_record(
                        read1, contig_dict[read1.reference_id], bam_out, read_length
                    )
                if read2:
                    self.write_bam_record(
                        read2, contig_dict[read2.reference_id], bam_out, read_length
                    )
        bam_out.close()

        _LOG.info(f"Bam written in: {(time.time() - t)/60:.2f} m")

    def write_bam_record(
        self, read: Read, contig_id: int, bam_handle: bgzf.BgzfWriter, read_length: int
    ):
        """
        Takes a read object and writes it out as a bam record

        :param read: a read object containing everything we need to write it out.
        :param contig_id: the index of the reference for this
        :param bam_handle: the handle of the file object to write to.
        :param read_length: the length of the read to output
        """
        read_bin = reg2bin(read.position, read.end_point)

        mate_position = read.get_mpos()
        flag = read.calculate_flags(self.paired)
        template_length = read.get_tlen()
        alt_sequence = read.read_sequence

        cigar = read.make_cigar()

        cig_letters = re.split(r"\d+", cigar)[1:]
        cig_numbers = [int(n) for n in re.findall(r"\d+", cigar)]
        cig_ops = len(cig_letters)

        next_ref_id = contig_id

        if not mate_position:
            next_pos = 0
            template_length = 0
        else:
            next_pos = mate_position

        encoded_cig = bytearray()
        for i in range(cig_ops):
            encoded_cig.extend(
                pack("<I", (cig_numbers[i] << 4) + CIGAR_PACKED[cig_letters[i]])
            )
        encoded_seq = bytearray()
        encoded_len = (read_length + 1) // 2
        seq_len = read_length
        if seq_len & 1:
            alt_sequence += "="
        for i in range(encoded_len):
            # if self.debug:
            #     # Note: trying to remove all this part
            encoded_seq.extend(
                pack(
                    "<B",
                    (SEQ_PACKED[alt_sequence[2 * i].capitalize()] << 4)
                    + SEQ_PACKED[alt_sequence[2 * i + 1].capitalize()],
                )
            )

        # apparently samtools automatically adds 33 to the quality score string...
        encoded_qual = "".join(
            [chr(ord(n) - 33) for n in read.read_quality_string[:read_length]]
        )

        """
        block_size = 4 +		# refID 		int32
                     4 +		# pos			int32
                     4 +		# bin_mq_nl		uint32
                     4 +		# flag_nc		uint32
                     4 +		# l_seq			int32
                     4 +		# next_ref_id	int32
                     4 +		# next_pos		int32
                     4 +		# tlen			int32
                     len(readName)+1 +
                     len(encoded cigar) +
                     encoded_len +
                     len(seq)
        """

        block_size = (
            32
            + len(read.name)
            + 1
            + len(encoded_cig)
            + len(encoded_seq)
            + len(read.read_quality_string)
        )

        bam_handle.write(
            (
                pack("<i", block_size)
                + pack("<i", contig_id)
                + pack("<i", read.position + 1)
                + pack(
                    "<I",
                    (read_bin << 16) + (read.mapping_quality << 8) + len(read.name) + 1,
                )
                + pack("<I", (flag << 16) + cig_ops)
                + pack("<i", seq_len)
                + pack("<i", next_ref_id)
                + pack("<i", next_pos)
                + pack("<i", template_length)
                + read.name.encode("utf-8")
                + b"\0"
                + encoded_cig
                + encoded_seq
                + encoded_qual.encode("utf-8")
            )
        )
